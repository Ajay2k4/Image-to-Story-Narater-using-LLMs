import time
import os
import requests
import json
from dotenv import load_dotenv, find_dotenv
from typing import Any
from transformers import pipeline
from langchain import PromptTemplate, LLMChain

load_dotenv(find_dotenv())
HUGGINGFACE_API_TOKEN = os.getenv("huggingface_key")
OPENAI_API_KEY = '1a9FVQMs6oYNn2uTFmZUTws5tdLD1K6vKWZYTQc8FatQouuQpteYJQQJ99AJACYeBjFXJ3w3AAABACOGMSJx'


def progress_bar(amount_of_time: int) -> None:
    """
    A very simple progress bar that increases over time.
    :param amount_of_time: Time taken for the progress bar to complete.
    """
    for percent_complete in range(amount_of_time):
        time.sleep(0.04)
    time.sleep(1)


def generate_text_from_image(url: str) -> str:
    """
    Uses the BLIP model to generate text from an image.
    :param url: Image location.
    :return: Generated text from the image.
    """
    image_to_text: Any = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base")
    generated_text: str = image_to_text(url)[0]["generated_text"]

    print(f"IMAGE INPUT: {url}")
    print(f"GENERATED TEXT OUTPUT: {generated_text}")
    return generated_text


import requests

# Set the endpoint and API key for Azure OpenAI
api_key = '1a9FVQMs6oYNn2uTFmZUTws5tdLD1K6vKWZYTQc8FatQouuQpteYJQQJ99AJACYeBjFXJ3w3AAABACOGMSJx'  # Use Key1 or Key2
endpoint = "https://openairvu.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-08-01-preview"

def generate_story_from_text(generated_text: str) -> str:
    """
    Function to generate a story from text using the Azure OpenAI API.
    
    Args:
        prompt (str): You are a creative story teller using one line text.
    
    Returns:
        str: The generated story or an error message.
    """
    
    # Define the headers with the API key for authentication
    headers = {
        "Content-Type": "application/json",
        "api-key": api_key  # Use either Key1 or Key2
    }
    prompt=('You are the creative story generater using the input:'+(generated_text))
    
    # Define the data payload for the request
    data = {
        "messages": [{"role": "user", "content": prompt}],  # Chat format for the prompt
        "max_tokens": 200,  # Max length for the generated response (adjust as needed)
        "temperature": 0.7  # Adjust temperature for creativity
    }

    try:
        # Make the POST request to the Azure OpenAI API
        response = requests.post(endpoint, headers=headers, json=data)
        
        # Check if the response is successful
        if response.status_code == 200:
            response_data = response.json()
            # Extract generated content based on the expected response structure
            generated_story = response_data.get("choices", [{}])[0].get("message", {}).get("content", "")
            return generated_story
        else:
            return f"Error: {response.status_code}, {response.text}"

    except Exception as e:
        return f"An error occurred: {str(e)}"


def generate_speech_from_text(message: str) -> None:
    """
    Uses ESPnet text-to-speech model from HuggingFace to generate audio.
    :param message: Short story generated by the GPT model.
    """
    API_URL: str = "https://api-inference.huggingface.co/models/espnet/kan-bayashi_ljspeech_vits"
    headers: dict = {"Authorization": f"Bearer {HUGGINGFACE_API_TOKEN}"}
    payloads: dict = {"inputs": message}

    # Make the POST request
    response = requests.post(API_URL, headers=headers, json=payloads)
    
    # Check if the response is valid
    if response.status_code == 200:
        # Save the audio content as a file with a specified format
        with open("Generated_audio.wav", "wb") as file:
            file.write(response.content)
    else:
        print(f"Error: {response.status_code} - {response.text}")





        
